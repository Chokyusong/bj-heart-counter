# app.py
import io, re, csv, zipfile, unicodedata
import numpy as np
import pandas as pd
import streamlit as st
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter

st.set_page_config(page_title="BJë³„ í•˜íŠ¸ ì •ë¦¬ â€” ê´€ë¦¬ììš© & BJìš©", layout="wide")
st.title("BJë³„ í•˜íŠ¸ ì •ë¦¬ ìë™í™”")
st.caption("CSV/XLSX ì—…ë¡œë“œ â†’ ì°¸ì—¬BJë³„ ê°œë³„ ì—‘ì…€ íŒŒì¼ ìƒì„± (ì¢Œ: ê´€ë¦¬ììš©, ìš°: BJìš©)  / ëª¨ë“  ì²˜ë¦¬ ë©”ëª¨ë¦¬ ì „ìš©")

uploaded = st.file_uploader("CSV ë˜ëŠ” ì—‘ì…€(.xlsx) ì—…ë¡œë“œ", type=["csv", "xlsx"])
sheet_name = st.text_input("ì‹œíŠ¸ ì´ë¦„ (ì—‘ì…€ì¼ ë•Œë§Œ, ë¹„ìš°ë©´ ì²« ì‹œíŠ¸)", value="")

# -------------------- autosize helpers --------------------
def visual_len(val) -> int:
    """í•œê¸€/ì „ê°/ì´ëª¨ì§€ë¥¼ ë„“ê²Œ ê³„ì‚°í•˜ëŠ” í‘œì‹œ í­ ê¸¸ì´."""
    s = str(val) if val is not None else ""
    w = 0
    for ch in s:
        # east_asian_width: F/W/A(ì „ê°/ë„“ì€/ëª¨í˜¸)ëŠ” 2ì¹¸
        if unicodedata.east_asian_width(ch) in ("F", "W", "A"):
            w += 2
        elif ord(ch) >= 0x1F300:  # ì´ëª¨ì§€ ëŒ€ëµ ì˜ì—­
            w += 2
        else:
            w += 1
    return w

def autosize_columns(wb, min_w=12, max_w=80, pad=2):
    for ws in wb.worksheets:
        for col in ws.columns:
            letter = get_column_letter(col[0].column)
            max_width = 0
            for cell in col:
                if cell.value is not None:
                    max_width = max(max_width, visual_len(cell.value))
            ws.column_dimensions[letter].width = max(min_w, min(max_width + pad, max_w))

def sanitize(name: str) -> str:
    return re.sub(r'[\\/*?:\[\]]', "_", str(name))[:31] or "BJ"

@st.cache_data(show_spinner=False, persist=False, ttl=0, max_entries=10)
def read_any_table(uploaded_file, sheet: str | int | None):
    name = (uploaded_file.name or "").lower()
    if name.endswith(".xlsx"):
        return pd.read_excel(uploaded_file, sheet_name=(sheet if str(sheet).strip() else 0))
    raw = uploaded_file.read(); uploaded_file.seek(0)
    for enc in ["utf-8", "utf-8-sig", "cp949", "euc-kr"]:
        try:
            text = raw.decode(enc)
            try:
                dialect = csv.Sniffer().sniff(text[:4000], delimiters=[",", "\t", ";", "|"])
                sep = dialect.delimiter
            except Exception:
                sep = ","
            return pd.read_csv(io.StringIO(text), sep=sep)
        except Exception:
            continue
    raise ValueError("CSV ì¸ì½”ë”©/êµ¬ë¶„ì í•´ì„ ì‹¤íŒ¨")

# -------------------- core --------------------
def preprocess(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).strip() for c in df.columns]
    col_bj    = next((c for c in df.columns if c == "ì°¸ì—¬BJ"), None)
    col_heart = next((c for c in df.columns if c == "í›„ì›í•˜íŠ¸"), None)
    col_mix   = next((c for c in df.columns if c == "í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)"), None)
    if not (col_bj and col_heart and col_mix):
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: ì°¸ì—¬BJ={col_bj}, í›„ì›í•˜íŠ¸={col_heart}, í›„ì› ì•„ì´ë””(ë‹‰ë„¤ì„)={col_mix}")

    df[col_bj] = df[col_bj].astype(str).str.strip()
    df[col_heart] = df[col_heart].astype(str).str.replace(",", "", regex=False)
    df[col_heart] = pd.to_numeric(df[col_heart], errors="coerce").fillna(0).astype(int)
    df[col_mix] = df[col_mix].astype(str).str.strip()

    sp = df[col_mix].str.extract(r'^\s*(?P<ID>[^()]+?)(?:\((?P<NICK>.*)\))?\s*$')
    df["ID"] = (sp["ID"].fillna("")
                .str.replace("\u200b","",regex=False)
                .str.replace("\ufeff","",regex=False)
                .str.replace("ï¼ ","@",regex=False)
                .str.strip())
    df["ë‹‰ë„¤ì„"] = sp["NICK"].fillna("").str.strip()

    base = (
        df.groupby([col_bj, "ID", "ë‹‰ë„¤ì„"], as_index=False)[col_heart]
          .sum()
          .rename(columns={col_bj:"ì°¸ì—¬BJ", col_heart:"í›„ì›í•˜íŠ¸"})
    )
    return base

def _xlsx_bytes_from_df(writer_fn) -> bytes:
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as w:
        writer_fn(w)
    bio.seek(0)
    wb = load_workbook(bio)
    autosize_columns(wb)  # ê°œì„ ëœ ìë™ì—´í­ ì‚¬ìš©
    out = io.BytesIO(); wb.save(out); out.seek(0)
    return out.getvalue()

def make_bj_excel(bj_name: str, sub_df: pd.DataFrame, admin: bool) -> bytes:
    """admin=True: A~Eì—´(êµ¬ë¶„/í•©ê³„ í¬í•¨) / admin=False: A~Cì—´ë§Œ"""
    sub = sub_df.copy()
    sub["is_aff"] = sub["ID"].str.contains("@")
    gen = sub[~sub["is_aff"]].sort_values("í›„ì›í•˜íŠ¸", ascending=False)[["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]].copy()
    aff = sub[ sub["is_aff"]].sort_values("í›„ì›í•˜íŠ¸", ascending=False)[["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]].copy()
    gsum = int(gen["í›„ì›í•˜íŠ¸"].sum()) if not gen.empty else 0
    asum = int(aff["í›„ì›í•˜íŠ¸"].sum()) if not aff.empty else 0
    total = gsum + asum
    sheet = sanitize(bj_name)

    def _write(w):
        # 1í–‰: B=ì°¸ì—¬BJ, C=ì´í•©
        if admin:
            row1 = pd.DataFrame([[ "", bj_name, total, "", "" ]],
                                columns=["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸","êµ¬ë¶„","í•©ê³„"])
        else:
            row1 = pd.DataFrame([[ "", bj_name, total ]],
                                columns=["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"])
        row1.to_excel(w, sheet_name=sheet, index=False, header=False, startrow=0)

        # 2í–‰: í—¤ë”
        if admin:
            pd.DataFrame(columns=["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸","êµ¬ë¶„","í•©ê³„"]).to_excel(
                w, sheet_name=sheet, index=False, startrow=1
            )
        else:
            pd.DataFrame(columns=["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]).to_excel(
                w, sheet_name=sheet, index=False, startrow=1
            )

        row = 2

        # ì¼ë°˜ ë¸”ë¡
        if not gen.empty:
            blk = gen.copy()
            if admin:
                blk["êµ¬ë¶„"] = ""; blk["í•©ê³„"] = ""
                blk.iloc[0, blk.columns.get_loc("êµ¬ë¶„")] = "ì¼ë°˜í•˜íŠ¸"
                blk.iloc[0, blk.columns.get_loc("í•©ê³„")] = gsum
            blk.to_excel(w, sheet_name=sheet, index=False, header=False, startrow=row)
            row += len(blk)

        # ì œíœ´ ë¸”ë¡
        if not aff.empty:
            blk = aff.copy()
            if admin:
                blk["êµ¬ë¶„"] = ""; blk["í•©ê³„"] = ""
                blk.iloc[0, blk.columns.get_loc("êµ¬ë¶„")] = "ì œíœ´í•˜íŠ¸"
                blk.iloc[0, blk.columns.get_loc("í•©ê³„")] = asum
            blk.to_excel(w, sheet_name=sheet, index=False, header=False, startrow=row)

    return _xlsx_bytes_from_df(_write)

def build_file_sets(base: pd.DataFrame):
    summary = base.groupby("ì°¸ì—¬BJ", as_index=False)["í›„ì›í•˜íŠ¸"].sum().sort_values("í›„ì›í•˜íŠ¸", ascending=False)

    def make_summary_bytes() -> bytes:
        return _xlsx_bytes_from_df(lambda w: summary.to_excel(w, sheet_name="ìš”ì•½", index=False))

    def pack_zip(files: dict[str, bytes]) -> bytes:
        zbio = io.BytesIO()
        with zipfile.ZipFile(zbio, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            for fname, data in files.items():
                zf.writestr(fname, data)
        zbio.seek(0); return zbio.getvalue()

    # ê´€ë¦¬ììš©
    admin_files: dict[str, bytes] = {"ìš”ì•½.xlsx": make_summary_bytes()}
    for bj in summary["ì°¸ì—¬BJ"]:
        sub = base[base["ì°¸ì—¬BJ"] == bj][["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]]
        admin_files[f"{sanitize(bj)}.xlsx"] = make_bj_excel(str(bj), sub, admin=True)
    admin_zip = pack_zip(admin_files)

    # BJìš©
    bj_files: dict[str, bytes] = {"ìš”ì•½.xlsx": make_summary_bytes()}
    for bj in summary["ì°¸ì—¬BJ"]:
        sub = base[base["ì°¸ì—¬BJ"] == bj][["ID","ë‹‰ë„¤ì„","í›„ì›í•˜íŠ¸"]]
        bj_files[f"{sanitize(bj)}.xlsx"] = make_bj_excel(str(bj), sub, admin=False)
    bj_zip = pack_zip(bj_files)

    return (admin_files, admin_zip), (bj_files, bj_zip)

# -------------------- run --------------------
if uploaded:
    try:
        df_in = read_any_table(uploaded, sheet_name if uploaded.name.lower().endswith(".xlsx") else None)
        base = preprocess(df_in)
        (admin_files, admin_zip), (bj_files, bj_zip) = build_file_sets(base)

        left, right = st.columns(2, gap="large")

        with left:
            st.subheader("ê´€ë¦¬ììš© (êµ¬ë¶„/í•©ê³„ í¬í•¨)")
            st.download_button("ğŸ“¦ ê´€ë¦¬ììš© ZIP ë‹¤ìš´ë¡œë“œ", data=admin_zip,
                               file_name="BJë³„_ê´€ë¦¬ììš©.zip", mime="application/zip",
                               use_container_width=True, key="zip-admin")
            st.divider(); st.markdown("**ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ**")
            for i, (fname, data) in enumerate(admin_files.items()):
                st.download_button(f"â¬‡ï¸ {fname}", data=data,
                                   file_name=fname,
                                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                   key=f"admin-{i}-{fname}")

        with right:
            st.subheader("BJìš© (D/E ì—†ìŒ)")
            st.download_button("ğŸ“¦ BJìš© ZIP ë‹¤ìš´ë¡œë“œ", data=bj_zip,
                               file_name="BJë³„_BJìš©.zip", mime="application/zip",
                               use_container_width=True, key="zip-bj")
            st.divider(); st.markdown("**ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ**")
            for i, (fname, data) in enumerate(bj_files.items()):
                st.download_button(f"â¬‡ï¸ {fname}", data=data,
                                   file_name=fname,
                                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                   key=f"bj-{i}-{fname}")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {e}")
    finally:
        try:
            uploaded.close()
        except Exception:
            pass
        uploaded = None
else:
    st.info("CSV/XLSX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì¢Œ(ê´€ë¦¬ììš©), ìš°(BJìš©)ìœ¼ë¡œ ê°ê° ë‚´ë ¤ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  íŒŒì¼ì€ ì„œë²„ì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
